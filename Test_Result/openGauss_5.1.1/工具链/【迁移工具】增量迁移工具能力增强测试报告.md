

版权所有 © 2023 openGauss社区 您对“本文档”的复制、使用、修改及分发受知识共享(Creative Commons)署名—相同方式共享4.0国际公共许可协议(以下简称“CC BY-SA 4.0”)的约束。为了方便用户理解，您可以通过访问[https://creativecommons.org/licenses/by-sa/4.0/](https://gitee.com/link?target=https%3A%2F%2Fcreativecommons.org%2Flicenses%2Fby-sa%2F4.0%2F) 了解CC BY-SA 4.0的概要 (但不是替代)。CC BY-SA 4.0的完整协议内容您可以访问如下网址获取：[https://creativecommons.org/licenses/by-sa/4.0/legalcode。](https://gitee.com/link?target=https%3A%2F%2Fcreativecommons.org%2Flicenses%2Fby-sa%2F4.0%2Flegalcode%E3%80%82)

修订记录

| 日期       | 修订 版本 | 修改描述 | 作者        |
| ---------- | --------- | -------- | ----------- |
| 2023-11-15 | V1.0      | 初稿     | houshaolong |

关键词：

增量迁移、按表回放

摘要：

支持回放模式可按表进行回放、抽取kafka数据流量控制、基于系统资源动态调整启动参数、支持jdbc超时重连以适应迁移过程中长时间无增量数据更新的情形

缩略语清单：

| 缩略语 | 英文全名                 | 中文解释   |
| ------ | ------------------------ | ---------- |
| `tps`  | `Transaction Per Second` | 每秒事务数 |

# 1 特性概述



# 2 特性测试信息

##### 功能测试

| 版本名称                       | 测试起始时间 | 测试结束时间 |
| ------------------------------ | ------------ | ------------ |
| openGauss 5.1.1 build 812682c6 | 2023-10-21   | 2023-11-8    |
| openGauss 5.1.1 build de769317 | 2023-11-9    | 2023-11-23   |
| MySQL 5.7.35                   | 2023-10-21   | 2023-11-23   |
| chameleon 5.1.1                | 2023-10-21   | 2023-11-23   |
| Debezium v1.8.1.Final          | 2023-10-21   | 2023-11-23   |

##### 性能测试

| 版本名称                       | 测试起始时间 | 测试结束时间 |
| ------------------------------ | ------------ | ------------ |
| openGauss 5.1.1 build 5099d94c | 2023-11-18   | 2023-11-18   |
| MySQL 5.7.27                   | 2023-11-18   | 2023-11-18   |
| chameleon 5.1.1                | 2023-11-18   | 2023-11-18   |
| Debezium v1.8.1.Final          | 2023-11-18   | 2023-11-18   |
| sysbench 1.0.20                | 2023-11-18   | 2023-11-18   |

硬件环境信息：

##### 功能测试

| 环境信息 | 配置信息                                                     | 备注 |
| -------- | ------------------------------------------------------------ | ---- |
| 虚拟机   | Intel(R) Xeon(R) Gold 6266C CPU @ 3.00GHz 4核 内存：32GB 硬盘：300GB OS：CentOS Linux release 7.6.1810 (Core) |      |

##### 性能测试

| 硬件型号                 | 硬件配置信息                                                 | 备注                                                         |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| TaiShan 200 (Model 2280) | Architecture：aarch64 CPU：kunpeng-920 7260 2p 128核 内存：32 * 32GB 硬盘：3 * 2.9TB OS：openEuler release 20.03 (LTS-SP1) | openGauss 5.1.1 build 5099d94c<br>debezium-connector-MySQL-1.8.1.Final-plugin.tar.gz |
| TaiShan 200 (Model 2280) | Architecture：aarch64 CPU：kunpeng-920 7260 2p 128核 内存：24 * 32GB 硬盘：3 * 2.9TB OS：openEuler release 20.03 (LTS-SP1) | MySQL 5.7.27<br>chameleon 3.1.1                              |
| TaiShan 200 (Model 2280) | Architecture：aarch64 CPU：kunpeng-920 7260 2p 128核 内存：24 * 32GB 硬盘：3 * 2.9TB OS：openEuler release 20.03 (LTS-SP1) | sysbench 1.0.20                                              |

# 3 测试结论概述

## 3.1 测试整体结论

增量迁移工具能力增强，共执行用例42个，主要覆盖了功能测试、性能测试、资料测试以及常稳测试。功能测试主要覆盖source端和sink端参数有效性，手动kill sink端和sourc端进程再恢复后数据是否能完成迁移且不重复，以及增量迁移后数据类型兼容性。性能测试，在高性能机器下，设置按表回放，开启增量迁移，通过sysbench工具压测数据，待数据回放完成，计算迁移效率。资料测试覆盖校验资料的描述是否完整。累计发现缺陷单5个，5个缺陷已解决，回归通过，整体质量良好。

## 3.2 约束说明

1、MySQL 5.7及以上版本

2、MySQL参数设置： log_bin=ON,  binlog_format=ROW,  binlog_row_image=FULL,  gtid_mode = ON，若未设置gtid_mode = OFF，则sink端回放退化为串行回放，会降低在线迁移性能

3、增量迁移是直接透传DDL的，对于openGauss侧语法和MySQL侧语法不一样的，迁移失败

4、启动增量迁移，先启动source端，再启动sink端，confluent/confluent-5.5.1/etc/schema-registry/connect-avro-standalone.properties文件rest.port需配置不同端口

5、为保证事务的顺序性，kafka_2.12-3.6.0/config/server.properties文件num.partitions参数必须设置为1

6、性能测试对硬件系统有较高要求，仅insert和混合场景迁移性能达到3w tps且必须进行性能调优

* mysql高性能配置，binlog位置、安装目录、数据目录分别部署在3个不同的NVME盘
* openGauss侧openGauss高性能配置，pg_xlog、安装目录、数据目录分别部署在3个不同的NVME盘
* 在java11环境上运行在线迁移工具

## 3.3 遗留问题分析

### 3.3.1 遗留问题影响以及规避措施

| 问题单号 | 问题描述 | 问题级别 | 问题影响和规避措施 | 当前状态 |
| -------- | -------- | -------- | ------------------ | -------- |
| N/A      | N/A      | N/A      | N/A                | N/A      |

### 3.3.2 问题统计

|        | 问题总数 | 严重 | 主要 | 次要 | 不重要 |
| ------ | -------- | ---- | ---- | ---- | ------ |
| 数目   | 5        | 0    | 1    | 4    | 0      |
| 百分比 | 100%     | 0%   | 20%  | 80%  | 0%     |

### 3.3.3 问题单汇总

| 序号 | issue号                                                      | 级别 | 问题简述                                                     | 状态   | 备注 |
| ---- | ------------------------------------------------------------ | ---- | ------------------------------------------------------------ | ------ | ---- |
| 1    | [I8DKL8](https://e.gitee.com/opengaussorg/issues/list?issue=I8DKL8) | 主要 | 【测试类型：工具功能】【测试版本：5.1.1】增量迁移执行drop语句时，sink端报错 | 已验收 |      |
| 2    | [I8DM8M](https://e.gitee.com/opengaussorg/issues/list?issue=I8DM8M) | 次要 | 【测试类型：工具功能】【测试版本：5.1.1】source端参数kafka.bootstrap.server配置为无效值时，启动报错，未将无效值转换为默认值 | 已验收 |      |
| 3    | [I8FPGB](https://e.gitee.com/opengaussorg/issues/list?issue=I8FPGB) | 次要 | 【测试类型：工具功能】【测试版本：5.1.1】增量迁移时，source端偶现回放速率为负数 | 已验收 |      |
| 4    | [I8G35O](https://e.gitee.com/opengaussorg/issues/list?issue=I8G35O) | 次要 | 【测试类型：工具功能】【测试版本：5.1.1】增量迁移，source端偶现binlog解析失败 | 已验收 |      |
| 5    | [I8FPRB](https://e.gitee.com/opengaussorg/issues/list?issue=I8FPRB) | 次要 | 【测试类型：资料】【测试版本：5.1.1】debezium迁移部分资料描述不准确 | 已验收 |      |

# 4 测试执行

## 4.1 功能测试实现步骤

1、修改mysql-source.properties文件中参数provide.transaction.metadata值为false

2、MySQL数据库创建表，插入数据

3、使用chameleon工具进行数据的离线迁移

```shell
chameleon create_replica_schema --config default --debug
chameleon add_source --config default --source MySQL --debug
chameleon init_replica --config default --source MySQL --debug
```

4、开启增量迁移

(1)启动zookeeper

```shell
cd  kafka_2.12-3.6.0
./bin/zookeeper-server-start.sh ./config/zookeeper.properties
```

(2)启动kafka

```shell
cd  kafka_2.12-3.6.0
./bin/kafka-server-start.sh ./config/server.properties
```

(3)注册schema

```shell
cd confluent-5.5.1
./bin/schema-registry-start etc/schema-registry/schema-registry.properties
```

(4)启动kafka-connect source端

```shell
cd confluent-5.5.1
./bin/connect-standalone etc/schema-registry/connect-avro-standalone.properties etc/kafka/mysql-source.properties
```

(5)启动kafka-connect sink端

```
cd confluent-5.5.1
./bin/connect-standalone etc/schema-registry/connect-avro-standalone-1.properties etc/kafka/mysql-sink.properties
```

5、MySQL数据库执行DDL或DML操作

6、openGauss数据库查看迁移情况

### 4.1.1 功能测试-配置文件参数测试

| 测试步骤                                                     | 测试结果                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1. 开启增量迁移，sink端配置不同参数值，启动迁移，查看不同参数设置下是否报错 | 执行25条用例，执行结果符合预期，测试通过，发现个bug1个，1个问题已解决回归通过 |

### 4.1.2 功能测试-增量迁移功能测试

| 测试步骤                                                     | 测试结果                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1. 迁移过程中，kill -9 、ctrl c、sink端进程或者数据库进程，待恢复后重新迁移，查看迁移过程中报错以及提示信息是否明确<br /> 2. opengauss端查看数据是否迁移完整且不重复<br />3.增量迁移数据类型测试 | 执行16条用例，执行结果符合预期，测试通过，发现4个bug，4个问题已解决回归通过 |



## 4.2 性能测试实现步骤

1、sysbench执行prepare命令，为源端数据集准备数据

2、 开启在线复制依次启动zookeeper，kafka，注册schema，绑核启动source端，绑核启动sink端

3、 sysbench执行run命令，给源端压入数据

4、 统计迁移工具日志，得到迁移效率(事务数/时间)

### 4.2.1性能测试

| 测试步骤                                                     | 测试结果                                |
| ------------------------------------------------------------ | --------------------------------------- |
| 1. 开启增量迁移，sysbench向MySQL压测数据<br /> 2. 查看迁移日志，计算迁移性能 | 执行1条用例，执行结果符合预期，测试通过 |

## 4.3 资料测试

| 测试步骤                   | 测试结果                   |
| -------------------------- | -------------------------- |
| 1. 文档描述<br>2. 文档示例 | 文档描述准确，示例正确无误 |

## 4.4 测试数据统计

根据用例进行测试验证，结果如下：

| 版本名称                       | 测试用例数 | 用例执行结果            | 发现问题单数 |
| ------------------------------ | ---------- | ----------------------- | ------------ |
| openGauss 5.1.1 build 812682c6 | 41         | Passed:39<br/>Failed:2  | 1            |
| openGauss 5.1.1 build de769317 | 42         | Passed:38<br/>Failed: 4 | 4            |
| openGauss 5.1.1 build 24ebc36b | 42         | Passed:42<br/>Failed:0  | 0            |

*数据项说明：*

- 累计发现缺陷单5个，5个缺陷已解决且回归通过，其中一个为资料单
- 失败用例已在后续问题修复后，回归issue执行通过
- 缺陷密度：4(缺陷个数)2.307/kloc(代码行数)=1.733(个/kloc)

### 4.4.1 sysbench使用不同参数配置，所测得的平均迁移速度

#### 4.4.1.1 增量迁移性能测试结果

| lua模型                                                     | num-threads | oltp-tables-count | oltp-table-size | max-time | sysbench速度(w tps) | 平均迁移速度(w/tps) |
| ----------------------------------------------------------- | ----------- | ----------------- | --------------- | -------- | ------------------- | ------------------- |
| 混合场景(insert-30线程、update-index-10线程、delete-10线程) | 50          | 50                | 100000          | 50       |                     | 4.434               |
| 混合场景(insert-30线程、update-index-10线程、delete-10线程) | 50          | 50                | 100000          | 50       |                     | 4.598               |
| 混合场景(insert-30线程、update-index-10线程、delete-10线程) | 50          | 50                | 100000          | 50       |                     | 4.401               |

混合场景占比：

| 事务总数 | sysbench速率(w tps) | Insert事务数 | Insert速率 | Insert占比 | Update事务数 | Update速率 | Update占比 | Delete事务数 | Delete速率 | Delete占比 |
| -------- | ------------------- | ------------ | ---------- | ---------- | ------------ | ---------- | ---------- | ------------ | ---------- | ---------- |
| 11431249 | 6.219               | 2352215      | 4.704      | 20.6%      | 4331925      | 8.663      | 37.9%      | 4747109      | 9.493      | 41.5%      |

根据测试数据，分析可得：insert和混合场景增量迁移性能测试结果达到3w tps以上。



## 4.5 后续测试建议

1、测试复杂场景下工具功能和稳定性

# 5 附件

##  5.1 源代码及文档PR 

【迁移工具】增量迁移工具能力增强PR

 https://e.gitee.com/opengaussorg/repos/opengauss/debezium/pulls/154

【迁移工具】增量迁移工具能力增强资料PR

https://e.gitee.com/opengaussorg/repos/opengauss/debezium/pulls/179

## 5.2 30个线程，10张表，1000行数据，使用insert模型测试迁移效率

```shell
1.sysbench执行prepare命令，为mysql端准备数据
numactl -C 1-64 -m 0 ../sysbench oltp_insert.lua --mysql-host=20.20.20.115 --mysql-port=3352 --mysql-db=zengliang_b004 --table_size=1000 --tables=30 --threads=30 --time=50 --report-interval=1 --mysql-user=cha_test --mysql-password='Huawei@123' --db-driver=mysql prepare
2.通过chameleon离线迁移数据至openGauss端
chameleon init_replica --config default_zh --source MySQL --debug
3.开启增量迁移
--绑核启动source端
numactl -C 32-63 -m 0 ./bin/connect-standalone etc/schema-registry/connect-avro-standalone.properties etc/kafka/MySQL-source.properties
--绑核启动sink端
numactl -C 64-95 -m 0 ./bin/connect-standalone etc/schema-registry/connect-avro-standalone-zh.properties etc/kafka/MySQL-sink.properties
4.sysbench执行run命令，给mysql压入数据
numactl -C 1-64 -m 0 ../sysbench oltp_insert.lua --mysql-host=20.20.20.115 --mysql-port=3352 --mysql-db=zengliang_b004 --table_size=1000 --tables=30 --threads=30 --time=50 --report-interval=1 --mysql-user=cha_test --mysql-password='Huawei@123' --db-driver=mysql run > /usr2/yangyixiang/sysbench-1.0/src/lua/result/insert.log &&

numactl -C 1-64 -m 0 ../sysbench oltp_update_index.lua --mysql-host=20.20.20.115 --mysql-port=3352 --mysql-db=zengliang_b004 --table_size=1000 --tables=10 --threads=10 --time=50 --report-interval=1 --mysql-user=cha_test --mysql-password='Huawei@123' --db-driver=mysql run > /usr2/yangyixiang/sysbench-1.0/src/lua/result/update.log &&

numactl -C 1-64 -m 0 ../sysbench oltp_delete.lua --mysql-host=20.20.20.115 --mysql-port=3352 --mysql-db=zengliang_b004 --table_size=1000 --tables=10 --threads=10 --time=50 --report-interval=1 --mysql-user=cha_test --mysql-password='Huawei@123' --db-driver=mysql run > /usr2/yangyixiang/sysbench-1.0/src/lua/result/delete.log &&

5.source端解析的事务：
WARNING: have parsed 2325163 I/U/D/DDL events, and current time is 2023-11-13 14:18:53.524, and current speed is 53296
Nov 13, 2023 2:18:54 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2378274 I/U/D/DDL events, and current time is 2023-11-13 14:18:54.524, and current speed is 53102
Nov 13, 2023 2:18:55 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2431351 I/U/D/DDL events, and current time is 2023-11-13 14:18:55.524, and current speed is 53069
Nov 13, 2023 2:18:56 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2484417 I/U/D/DDL events, and current time is 2023-11-13 14:18:56.524, and current speed is 53057
Nov 13, 2023 2:18:57 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2537379 I/U/D/DDL events, and current time is 2023-11-13 14:18:57.524, and current speed is 52955
Nov 13, 2023 2:18:58 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2590377 I/U/D/DDL events, and current time is 2023-11-13 14:18:58.524, and current speed is 52991
Nov 13, 2023 2:18:59 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2643854 I/U/D/DDL events, and current time is 2023-11-13 14:18:59.524, and current speed is 53470
Nov 13, 2023 2:19:00 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2697473 I/U/D/DDL events, and current time is 2023-11-13 14:19:00.524, and current speed is 53611
Nov 13, 2023 2:19:01 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2751213 I/U/D/DDL events, and current time is 2023-11-13 14:19:01.525, and current speed is 53732
Nov 13, 2023 2:19:02 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2803827 I/U/D/DDL events, and current time is 2023-11-13 14:19:02.525, and current speed is 52605
Nov 13, 2023 2:19:03 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2857177 I/U/D/DDL events, and current time is 2023-11-13 14:19:03.525, and current speed is 53340
Nov 13, 2023 2:19:04 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2869300 I/U/D/DDL events, and current time is 2023-11-13 14:19:04.525, and current speed is 12117
Nov 13, 2023 2:19:05 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2910777 I/U/D/DDL events, and current time is 2023-11-13 14:19:05.526, and current speed is 41477
Nov 13, 2023 2:19:06 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 2964482 I/U/D/DDL events, and current time is 2023-11-13 14:19:06.526, and current speed is 53696
Nov 13, 2023 2:19:07 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3018097 I/U/D/DDL events, and current time is 2023-11-13 14:19:07.526, and current speed is 53605
Nov 13, 2023 2:19:08 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3071667 I/U/D/DDL events, and current time is 2023-11-13 14:19:08.526, and current speed is 53561
Nov 13, 2023 2:19:09 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3125060 I/U/D/DDL events, and current time is 2023-11-13 14:19:09.527, and current speed is 53384
Nov 13, 2023 2:19:10 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3178403 I/U/D/DDL events, and current time is 2023-11-13 14:19:10.527, and current speed is 53332
Nov 13, 2023 2:19:11 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3231797 I/U/D/DDL events, and current time is 2023-11-13 14:19:11.527, and current speed is 53388
Nov 13, 2023 2:19:12 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3284991 I/U/D/DDL events, and current time is 2023-11-13 14:19:12.527, and current speed is 53185
Nov 13, 2023 2:19:13 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3320955 I/U/D/DDL events, and current time is 2023-11-13 14:19:13.528, and current speed is 35957
Nov 13, 2023 2:19:14 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3338194 I/U/D/DDL events, and current time is 2023-11-13 14:19:14.528, and current speed is 17239
Nov 13, 2023 2:19:15 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3391231 I/U/D/DDL events, and current time is 2023-11-13 14:19:15.541, and current speed is 53029
Nov 13, 2023 2:19:16 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3446024 I/U/D/DDL events, and current time is 2023-11-13 14:19:16.541, and current speed is 54789
Nov 13, 2023 2:19:17 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3499096 I/U/D/DDL events, and current time is 2023-11-13 14:19:17.541, and current speed is 53064
Nov 13, 2023 2:19:18 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3552387 I/U/D/DDL events, and current time is 2023-11-13 14:19:18.541, and current speed is 53284
Nov 13, 2023 2:19:19 PM com.github.shyiko.mysql.binlog.BinaryLogClient$9 run
WARNING: have parsed 3605465 I/U/D/DDL events, and current time is 2023-11-13 14:19:19.541, and current speed is 53068

6.sink端回放的事务：
[2023-11-13 14:22:38,540] INFO have replayed 5639900 data, and current time is 2023-11-13 14:22:38.540, and current speed is 34758 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:39,541] INFO have replayed 5673436 data, and current time is 2023-11-13 14:22:39.541, and current speed is 33530 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:40,541] INFO have replayed 5707712 data, and current time is 2023-11-13 14:22:40.541, and current speed is 34273 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:41,541] INFO have replayed 5746825 data, and current time is 2023-11-13 14:22:41.541, and current speed is 39102 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:42,541] INFO have replayed 5788743 data, and current time is 2023-11-13 14:22:42.541, and current speed is 41918 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:43,542] INFO have replayed 5827828 data, and current time is 2023-11-13 14:22:43.542, and current speed is 39080 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:44,542] INFO have replayed 5870002 data, and current time is 2023-11-13 14:22:44.542, and current speed is 42169 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:45,542] INFO have replayed 5902605 data, and current time is 2023-11-13 14:22:45.542, and current speed is 32596 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:46,542] INFO have replayed 5938220 data, and current time is 2023-11-13 14:22:46.542, and current speed is 35613 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:47,543] INFO have replayed 5977345 data, and current time is 2023-11-13 14:22:47.543, and current speed is 39126 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:48,543] INFO have replayed 6018165 data, and current time is 2023-11-13 14:22:48.543, and current speed is 40818 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:49,543] INFO have replayed 6053669 data, and current time is 2023-11-13 14:22:49.543, and current speed is 35499 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:50,543] INFO have replayed 6089196 data, and current time is 2023-11-13 14:22:50.543, and current speed is 35518 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:51,544] INFO have replayed 6123421 data, and current time is 2023-11-13 14:22:51.544, and current speed is 34214 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
[2023-11-13 14:22:52,544] INFO have replayed 6157757 data, and current time is 2023-11-13 14:22:52.544, and current speed is 34333 (io.debezium.connector.mysql.sink.replay.table.TableReplayTask:557)
```

## 5.3 my.cnf配置文件参数设置

```
[client]
port=3396
socket=/usr2/qiuying/mysql/mysql.sock

[mysqld]
port=3396
basedir=/mysql/mysql-5.7.27-aarch64
datadir=/mysql/data
pid-file=/mysql/mysql.pid
socket=/mysql/mysql.sock
log_error=/mysql/error.log
log_bin = /mysql/binlog/mysql-bin
bind_address = xx.xx.xx.xx

binlog_row_image=FULL
server-id=1
max_binlog_size=1G
enforce_gtid_consistency=on
gtid_mode=on
binlog_format= ROW
max_allowed_packet=32M

max_connections=2000
back_log=4000
performance_schema=OFF
max_prepared_stmt_count=128000

#file
innodb_file_per_table
innodb_log_file_size=2048M
innodb_log_files_in_group=32
innodb_open_files=10000
table_open_cache_instances=64

#buffers
innodb_buffer_pool_size=230G
innodb_buffer_pool_instances=16
innodb_log_buffer_size=2048M

#tune
sync_binlog=0
innodb_flush_log_at_trx_commit=1
innodb_use_native_aio=1
innodb_spin_wait_delay=180
innodb_sync_spin_loops=25
innodb_flush_method=O_DIRECT
innodb_io_capacity=30000
innodb_io_capacity_max=40000
innodb_lru_scan_depth=9000
innodb_page_cleaners=16

#perf special
innodb_thread_concurrency=0
innodb_flush_neighbors=0
#innodb_write_io_threads=24
#innodb_read_io_threads=16
innodb_write_io_threads=50
innodb_read_io_threads=16
innodb_purge_threads=32

sql_mode=STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION,STRICT_ALL_TABLES
#skip_log_bin
ssl=0
table_open_cache=30000
max_connect_errors=2000
innodb_adaptive_hash_index=0
skip-name-resolve
```



## 5.4 postgresql.conf配置文件参数设置

```
max_connections = 4096
allow_concurrent_tuple_update = true
audit_enabled = off
cstore_buffers = 16MB
enable_alarm = off
enable_codegen = false
enable_data_replicate = off
full_page_writes = off
max_files_per_process = 100000
max_prepared_transactions = 2048
shared_buffers = 250GB
use_workload_manager = off
wal_buffers = 1GB
work_mem = 1MB
transaction_isolation = 'read committed'
default_transaction_isolation = 'read committed'
#synchronous_commit = on
#fsync = on
maintenance_work_mem = 2GB
vacuum_cost_limit = 10000
autovacuum = on
autovacuum_mode = vacuum
autovacuum_max_workers = 20
autovacuum_naptime = 5s
autovacuum_vacuum_cost_delay = 10
update_lockwait_timeout = 20min
enable_mergejoin = off
enable_nestloop = off
enable_hashjoin = off
enable_material = off
wal_log_hints = off
log_duration = off
checkpoint_timeout = 15min
autovacuum_vacuum_scale_factor = 0.1
autovacuum_analyze_scale_factor = 0.02
enable_save_datachanged_timestamp = false
enable_double_write = on
enable_incremental_checkpoint = on
enable_opfusion = on
advance_xlog_file_num = 100
numa_distribute_mode = 'all'
track_activities = on
enable_instr_track_wait = off
enable_instr_rt_percentile = off
track_counts = on
track_sql_count = off
enable_instr_cpu_timer = off
plog_merge_age = 0
session_timeout = 0
enable_instance_metric_persistent = off
enable_logical_io_statistics = off
enable_page_lsn_check = off
enable_user_metric_persistent = off
enable_xlog_prune = off
enable_resource_track = off
instr_unique_sql_count=0
remote_read_mode=non_authentication
wal_level = archive
hot_standby = off
hot_standby_feedback = off
client_min_messages = ERROR
log_min_messages = LOG
enable_asp = off
enable_bbox_dump = off
bgwriter_flush_after = 32
wal_keep_segments = 1025
enable_bitmapscan = off
enable_seqscan = off
enable_thread_pool = on
enable_stmt_track=false
bgwriter_delay = 5s
walwriter_sleep_threshold = 50000
xloginsert_locks=16
pagewriter_sleep = 10ms
incremental_checkpoint_timeout=120s
wal_file_init_num = 30
checkpoint_segments = 100000
gs_clean_timeout =0
track_counts=on
undo_zone_count=0
pagewriter_thread_num = 2
max_redo_log_size=400GB
max_io_capacity=1GB
walwriter_cpu_bind = 2
local_syscache_threshold = 32MB
enable_wdr_snapshot = off
```

